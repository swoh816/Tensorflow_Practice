{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. MNIST dataset\n",
    "\n",
    "In this tutorial, we will use `MNIST dataset` to make an algorithm that can distinguish numbers between 1~10.\n",
    "First, we need to download `MNIST dataset.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " There are 70,000 data points (i.e., images) in total: 55,000 training data points (mnist.train), 10,000 test data (mnist.test), and 5,000 validation data (mnist.validation).\n",
    "\n",
    "A MNIST data point has two parts: an image of handwritten digit (`mnist.X.images`), and a corresponding label (`mnist.X.labels`). X can be either `train`, `test`, or `validation`. Each image is `28x28` pixels, which is a array of 784 numbers (i.e., 784-dimensional vector space)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABrCAYAAABnlHmpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdebee369b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(mnist.train.images[0].reshape([28,28]))\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(mnist.train.images[1].reshape([28,28]))\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(mnist.train.images[2].reshape([28,28]))\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(mnist.train.images[3].reshape([28,28]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Step-by-step tutorial for building a model for number recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To set a certain dimensional variable without specific values (i.e., *placeholder*), you use `placeholder.` To see the benefits of using `placeholder`, see https://www.tensorflow.org/get_started/mnist/beginners.\n",
    "\n",
    "Here, we create a variable with zero row and 784 columns (784 is the number of features for MNIST dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.placeholder(tf.float32, [None, 784])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `None` means that a row dimsenion can be of any length.\n",
    "\n",
    "Next, we use `Variable` as a modifiable tensor that lives in TensorFlow's graph of interacting operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`W` has a shape of [784, 10] because it has 784 pixels (features) and 10 numbers (1~10). So, the output of `W*x + b` will be the probability of correspond to the numbers between 1~10.\n",
    "\n",
    "We use `tf.zeros` to fill `W` and `b` with zeros, but because `W` and `b` are what we are going to learn and thus change, the initial values don't matter much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement cross entropy, we need a placeholder for the correct answers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_ = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we can implement the cross-entropy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_*tf.log(y), reduction_indices=[1]))\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "### The above is a short for:\n",
    "# optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "# train_step = optimizer.minimize(cross_entropy).`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "for _ in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict = {x:batch_xs, y_:batch_ys})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluating our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.906\n"
     ]
    }
   ],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(sess.run(accuracy, feed_dict={x:mnist.test.images, y_:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9207\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "for _ in range(1000):\n",
    "  batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
